{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memoria Práctica 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autores: Román García y Patricia Losana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Datos import Datos\n",
    "from EstrategiaParticionado import *\n",
    "from Clasificador import *\n",
    "import numpy as np\n",
    "from sklearn import preprocessing \n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Particionado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las tres estrategias de particionado implementadas parten de la misma idea principal: dado el conjunto de datos dataset, se genera un array con tantos elementos como filas tenga el conjunto (es decir, los índices). Este array se va a permutar para evitar que las particiones sean generadas sin ningún tipo de sesgo, y, en función de la estrategia, se devolverán unos u otros índices para entrenamiento y pruebas, respectivamente.\n",
    "\n",
    "A continuación vamos a ver una descripción de los índices de train y test devueltos por cada uno de los métodos de particionado, y las principales ventajas y desventajas de los mismos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Validación Simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validación simple contiene un array de Particiones, con tantos elementos como valor tenga el atributo numeroParticiones. El valor 'porcentaje' especifica el porcentaje del array que va a formar parte de los índices de train, de forma que el resto de elementos formarán parte de los índices de test.\n",
    "\n",
    "Para facilitar la comprensión, se ha acompañado la explicación de una figura. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/Simple.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ventajas: es rápido y aleatorio\n",
    "\n",
    "Inconvenientes: los índices no se dividen de manera controlada. Aunque es improbable, puede darse el caso de que para las numeroParticiones veces que se repita la generación de particiones, los índices de Train y Test estén formados siempre por el mismo subconjunto de datos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Validación Cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validación cruzada contiene un array de Particiones, con tantos elementos como valor tenga el atributo numeroParticiones. El valor 'numeroParticiones' especifica el número de Particiones que se van a hacer del mismo tamaño del array. De esta manera, después de permutar, se iterará numeroParticiones veces y el número de iteración especificará el conjunto de índices que formarán parte de Test.\n",
    "\n",
    "Para facilitar la comprensión, se ha acompañado la explicación de una figura."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/Cruzada.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ventaja frente a Validación Simple: es mucho más controlada en cuanto a que tenemos la certeza de que todos los datos van a formar parte de los índices de prueba y entrenamiento, por lo que no hay tanto peligro de sobreaprendizaje.\n",
    "\n",
    "Un posible inconveniente es que sólo se permuta una vez y que los índices que formen parte del entrenamiento van a ser parecidos en todas las iteraciones (sólo cambiarán K elementos cada vez)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Validación por Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La estrategia de particionamiento de bootstrap es similar a la de Validación simple, con la diferencia de que los índices de Train se extraen de manera aleatoria con reemplazamiento (por tanto, puede darse el caso de entrenar varias veces con el mismo dato).\n",
    "\n",
    "Para lograr esto, se permuta el array de índices cada vez que se selecciona un elemento a incluir en la partición de entrenamiento (el proceso se repite numeroParticiones veces). Posteriormente, el resto de elementos que no se hayan seleccionado como índices de entrenamiento pasarán a formar parte de los índices de prueba.\n",
    "\n",
    "Ventaja: es totalmente aleatoria\n",
    "\n",
    "Inconveniente: está aún menos controlada que la validación Simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Naive-Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Resultados de ejecución de tic-tac-toe.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Datos(\"ConjuntosDatos/tic-tac-toe.data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validación Simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sin la corrección de Laplace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promedio del error =  0.36083550913838114 \n",
      "Desviación típica =  0.01414748530981103\n"
     ]
    }
   ],
   "source": [
    "estrategia = ValidacionSimple()\n",
    "clas = ClasificadorNaiveBayes()\n",
    "val = clas.validacion(estrategia,dataset,clas)\n",
    "media_error1 = np.mean(val)\n",
    "desv_error1 = np.std(val)\n",
    "\n",
    "print(\"Promedio del error = \", media_error1, \"\\nDesviación típica = \", desv_error1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Con la corrección de Laplace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promedio del error =  0.35404699738903395 \n",
      "Desviación típica =  0.005116427661165912\n"
     ]
    }
   ],
   "source": [
    "estrategia = ValidacionSimple()\n",
    "clas = ClasificadorNaiveBayes(laplace=True)\n",
    "val = clas.validacion(estrategia,dataset,clas)\n",
    "media_error2 = np.mean(val)\n",
    "desv_error2 = np.std(val)\n",
    "\n",
    "print(\"Promedio del error = \", media_error2, \"\\nDesviación típica = \", desv_error2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validación Cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sin la corrección de Laplace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promedio del error =  0.34652777777777777 \n",
      "Desviación típica =  0.2007208748455562\n"
     ]
    }
   ],
   "source": [
    "estrategia = ValidacionCruzada()\n",
    "clas = ClasificadorNaiveBayes()\n",
    "val = clas.validacion(estrategia,dataset,clas)\n",
    "media_error3 = np.mean(val)\n",
    "desv_error3 = np.std(val)\n",
    "\n",
    "print(\"Promedio del error = \", media_error3, \"\\nDesviación típica = \", desv_error3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Con la corrección de Laplace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promedio del error =  0.34652777777777777 \n",
      "Desviación típica =  0.21281181733814838\n"
     ]
    }
   ],
   "source": [
    "estrategia = ValidacionCruzada()\n",
    "clas = ClasificadorNaiveBayes(laplace=True)\n",
    "val = clas.validacion(estrategia,dataset,clas)\n",
    "media_error4 = np.mean(val)\n",
    "desv_error4 = np.std(val)\n",
    "\n",
    "print(\"Promedio del error = \", media_error4, \"\\nDesviación típica = \", desv_error4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validación por Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sin la corrección de Laplace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promedio del error =  0.2 \n",
      "Desviación típica =  0.24494897427831783\n"
     ]
    }
   ],
   "source": [
    "estrategia = ValidacionBootstrap()\n",
    "clas = ClasificadorNaiveBayes()\n",
    "val = clas.validacion(estrategia,dataset,clas)\n",
    "media_error5 = np.mean(val)\n",
    "desv_error5 = np.std(val)\n",
    "\n",
    "print(\"Promedio del error = \", media_error5, \"\\nDesviación típica = \", desv_error5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Con la corrección de Laplace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promedio del error =  0.3 \n",
      "Desviación típica =  0.24494897427831783\n"
     ]
    }
   ],
   "source": [
    "estrategia = ValidacionBootstrap()\n",
    "clas = ClasificadorNaiveBayes(laplace=True)\n",
    "val = clas.validacion(estrategia,dataset,clas)\n",
    "media_error6 = np.mean(val)\n",
    "desv_error6 = np.std(val)\n",
    "\n",
    "print(\"Promedio del error = \", media_error6, \"\\nDesviación típica = \", desv_error6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados de ejecución de german.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Datos(\"ConjuntosDatos/german.data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validación Simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sin la corrección de Laplace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promedio del error =  0.3165 \n",
      "Desviación típica =  0.013928388277184131\n"
     ]
    }
   ],
   "source": [
    "estrategia = ValidacionSimple()\n",
    "clas = ClasificadorNaiveBayes()\n",
    "val = clas.validacion(estrategia,dataset,clas)\n",
    "media_error = np.mean(val)\n",
    "desv_error = np.std(val)\n",
    "\n",
    "print(\"Promedio del error = \", media_error, \"\\nDesviación típica = \", desv_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Con la corrección de Laplace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promedio del error =  0.3015 \n",
      "Desviación típica =  0.012103718436910214\n"
     ]
    }
   ],
   "source": [
    "estrategia = ValidacionSimple()\n",
    "clas = ClasificadorNaiveBayes(laplace=True)\n",
    "val = clas.validacion(estrategia,dataset,clas)\n",
    "media_error = np.mean(val)\n",
    "desv_error = np.std(val)\n",
    "\n",
    "print(\"Promedio del error = \", media_error, \"\\nDesviación típica = \", desv_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validación Cruzada\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sin la corrección de Laplace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promedio del error =  0.29800000000000004 \n",
      "Desviación típica =  0.19077735714701574\n"
     ]
    }
   ],
   "source": [
    "estrategia = ValidacionCruzada()\n",
    "clas = ClasificadorNaiveBayes()\n",
    "val = clas.validacion(estrategia,dataset,clas)\n",
    "media_error = np.mean(val)\n",
    "desv_error = np.std(val)\n",
    "\n",
    "print(\"Promedio del error = \", media_error, \"\\nDesviación típica = \", desv_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Con la corrección de Laplace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promedio del error =  0.298 \n",
      "Desviación típica =  0.20198019704911666\n"
     ]
    }
   ],
   "source": [
    "estrategia = ValidacionCruzada()\n",
    "clas = ClasificadorNaiveBayes(laplace=True)\n",
    "val = clas.validacion(estrategia,dataset,clas)\n",
    "media_error = np.mean(val)\n",
    "desv_error = np.std(val)\n",
    "\n",
    "print(\"Promedio del error = \", media_error, \"\\nDesviación típica = \", desv_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validación por Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sin la corrección de Laplace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promedio del error =  0.3 \n",
      "Desviación típica =  0.24494897427831783\n"
     ]
    }
   ],
   "source": [
    "estrategia = ValidacionBootstrap()\n",
    "clas = ClasificadorNaiveBayes()\n",
    "val = clas.validacion(estrategia,dataset,clas)\n",
    "media_error = np.mean(val)\n",
    "desv_error = np.std(val)\n",
    "\n",
    "print(\"Promedio del error = \", media_error, \"\\nDesviación típica = \", desv_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Con la corrección de Laplace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promedio del error =  0.2 \n",
      "Desviación típica =  0.24494897427831783\n"
     ]
    }
   ],
   "source": [
    "estrategia = ValidacionBootstrap()\n",
    "clas = ClasificadorNaiveBayes(laplace=True)\n",
    "val = clas.validacion(estrategia,dataset,clas)\n",
    "media_error = np.mean(val)\n",
    "desv_error = np.std(val)\n",
    "\n",
    "print(\"Promedio del error = \", media_error, \"\\nDesviación típica = \", desv_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de los resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar, los errores promedios son relativamente bajos y no hay grandes cambios se aplique o no la corrección de Laplace.\n",
    "Las desviaciones típicas de los promedios son bastante altas en la estrategia de validación cruzada y por bootstrap. Este hecho no es sorprendente en el caso del bootstrap, ya que por la forma de seleccionar los datos de entrenamiento, podía no obte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Resultados de ejecución de tic-tac-toe.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Datos(\"ConjuntosDatos/tic-tac-toe.data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validación Simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sin la corrección de Laplace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error = 0.3203125\n"
     ]
    }
   ],
   "source": [
    "# Encode categorical integer features using a one-hot aka one-of-K scheme (categorical features)\n",
    "encAtributos = preprocessing.OneHotEncoder(categorical_features=dataset.nominalAtributos[:-1],sparse=False)\n",
    "# X contendra la matriz de atributos codificada\n",
    "X = encAtributos.fit_transform(dataset.datos[:,:-1])\n",
    "\n",
    "# Y contendra la clase de cada patron\n",
    "Y =dataset.datos[:,-1] \n",
    "\n",
    "#Discretos = MultinomialNB\n",
    "#para no Laplace -> alpha = 0 (pero el valor 0 da un warning)\n",
    "clf = MultinomialNB(alpha=1.0e-10)\n",
    "\n",
    "#Validacion Simple\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(X, Y, train_size = 0.6, test_size = 0.4 )\n",
    "\n",
    "#Entrena el clasificador a partir de xTrain e yTrain\n",
    "classifier = clf.fit(xTrain, yTrain)\n",
    "#Predice el resultado de xTest en base al entrenamiento\n",
    "pred = classifier.predict(xTest)\n",
    "\n",
    "# Calcula el error (1 - la precision de la clasificacion)\n",
    "error = 1  - accuracy_score(pred, yTest)\n",
    "print(\"Error =\", error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Con la corrección de Laplace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error = 0.3359375\n"
     ]
    }
   ],
   "source": [
    "# Encode categorical integer features using a one-hot aka one-of-K scheme (categorical features)\n",
    "encAtributos = preprocessing.OneHotEncoder(categorical_features=dataset.nominalAtributos[:-1],sparse=False)\n",
    "# X contendra la matriz de atributos codificada\n",
    "X = encAtributos.fit_transform(dataset.datos[:,:-1])\n",
    "\n",
    "# Y contendra la clase de cada patron\n",
    "Y =dataset.datos[:,-1] \n",
    "\n",
    "#Discretos = MultinomialNB\n",
    "#para Laplace -> alpha = 1\n",
    "clf = MultinomialNB(alpha=1)\n",
    "\n",
    "#Validacion Simple\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(X, Y, train_size = 0.6, test_size = 0.4 )\n",
    "\n",
    "#Entrena el clasificador a partir de xTrain e yTrain\n",
    "classifier = clf.fit(xTrain, yTrain)\n",
    "#Predice el resultado de xTest en base al entrenamiento\n",
    "pred = classifier.predict(xTest)\n",
    "\n",
    "# Calcula el error (1 - la precision de la clasificacion)\n",
    "error = 1  - accuracy_score(pred, yTest)\n",
    "print(\"Error =\", error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validación Cruzada\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sin la corrección de Laplace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promedio del error =  0.37965224841530354 \n",
      "Desviación típica =  0.07553484138584828\n"
     ]
    }
   ],
   "source": [
    "# Encode categorical integer features using a one-hot aka one-of-K scheme (categorical features)\n",
    "encAtributos = preprocessing.OneHotEncoder(categorical_features=dataset.nominalAtributos[:-1],sparse=False)\n",
    "# X contendra la matriz de atributos codificada\n",
    "X = encAtributos.fit_transform(dataset.datos[:,:-1])\n",
    "\n",
    "# Y contendra la clase de cada patron\n",
    "Y =dataset.datos[:,-1] \n",
    "\n",
    "#Discretos = MultinomialNB\n",
    "#para no Laplace -> alpha = 0\n",
    "clf = MultinomialNB(alpha=1.0e-10)\n",
    "\n",
    "#Validacion Cruzada: obtenemos los resultados de las predicciones de cv iteraciones\n",
    "pred_kfolds = cross_val_score(clf, X, Y, cv = 5)\n",
    "\n",
    "#Obtenemos el error de la media de las predicciones\n",
    "media_error = 1 - pred_kfolds.mean()\n",
    "\n",
    "#Obtenemos la desviacion tipica de las predicciones\n",
    "desv_error = pred_kfolds.std()\n",
    "\n",
    "print(\"Promedio del error = \", media_error, \"\\nDesviación típica = \", desv_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Con la corrección de Laplace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promedio del error =  0.37965224841530354 \n",
      "Desviación típica =  0.07553484138584828\n"
     ]
    }
   ],
   "source": [
    "# Encode categorical integer features using a one-hot aka one-of-K scheme (categorical features)\n",
    "encAtributos = preprocessing.OneHotEncoder(categorical_features=dataset.nominalAtributos[:-1],sparse=False)\n",
    "# X contendra la matriz de atributos codificada\n",
    "X = encAtributos.fit_transform(dataset.datos[:,:-1])\n",
    "\n",
    "# Y contendra la clase de cada patron\n",
    "Y =dataset.datos[:,-1] \n",
    "\n",
    "#Discretos = MultinomialNB\n",
    "#para Laplace -> alpha = 1\n",
    "clf = MultinomialNB(alpha=1)\n",
    "\n",
    "#Validacion Cruzada: obtenemos los resultados de las predicciones de cv iteraciones\n",
    "pred_kfolds = cross_val_score(clf, X, Y, cv = 5)\n",
    "\n",
    "#Obtenemos el error de la media de las predicciones\n",
    "media_error = 1 - pred_kfolds.mean()\n",
    "\n",
    "#Obtenemos la desviacion tipica de las predicciones\n",
    "desv_error = pred_kfolds.std()\n",
    "\n",
    "print(\"Promedio del error = \", media_error, \"\\nDesviación típica = \", desv_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Resultados de ejecución de german.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Datos(\"ConjuntosDatos/german.data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validación Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error = 0.4275\n"
     ]
    }
   ],
   "source": [
    "# Encode categorical integer features using a one-hot aka one-of-K scheme (categorical features)\n",
    "encAtributos = preprocessing.OneHotEncoder(categorical_features=dataset.nominalAtributos[:-1],sparse=False)\n",
    "# X contendra la matriz de atributos codificada\n",
    "X = encAtributos.fit_transform(dataset.datos[:,:-1])\n",
    "\n",
    "# Y contendra la clase de cada patron\n",
    "Y =dataset.datos[:,-1] \n",
    "\n",
    "#Continuos = GaussianNB\n",
    "clf = GaussianNB()\n",
    "\n",
    "#Validacion Simple\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(X, Y, train_size = 0.6 , test_size = 0.4)\n",
    "\n",
    "#Entrena el clasificador a partir de xTrain e yTrain\n",
    "classifier = clf.fit(xTrain, yTrain)\n",
    "#Predice el resultado de xTest en base al entrenamiento\n",
    "pred = classifier.predict(xTest)\n",
    "\n",
    "# Calcula el error (1 - la precision de la clasificacion)\n",
    "error = 1  - accuracy_score(pred, yTest)\n",
    "print(\"Error =\", error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validación Cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promedio del error =  0.33299999999999996 \n",
      "Desviación típica =  0.036551333764994115\n"
     ]
    }
   ],
   "source": [
    "# Encode categorical integer features using a one-hot aka one-of-K scheme (categorical features)\n",
    "encAtributos = preprocessing.OneHotEncoder(categorical_features=dataset.nominalAtributos[:-1],sparse=False)\n",
    "# X contendra la matriz de atributos codificada\n",
    "X = encAtributos.fit_transform(dataset.datos[:,:-1])\n",
    "\n",
    "# Y contendra la clase de cada patron\n",
    "Y =dataset.datos[:,-1] \n",
    "\n",
    "#Discretos = MultinomialNB\n",
    "#para no Laplace -> alpha = 0\n",
    "clf = GaussianNB()\n",
    "\n",
    "#Validacion Cruzada: obtenemos los resultados de las predicciones de cv iteraciones\n",
    "pred_kfolds = cross_val_score(clf, X, Y, cv = 5)\n",
    "\n",
    "#Obtenemos el error de la media de las predicciones\n",
    "media_error = 1 - pred_kfolds.mean()\n",
    "\n",
    "#Obtenemos la desviacion tipica de las predicciones\n",
    "desv_error = pred_kfolds.std()\n",
    "\n",
    "print(\"Promedio del error = \", media_error, \"\\nDesviación típica = \", desv_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de los resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar, en generar el promedio de error en la librería sklearn es parecido, o incluso peor, que los promedios obtenidos por nuestro clasificador. \n",
    "Sin embargo, las desviaciones de la media son menores que nuestro clasificador, lo que quiere decir que los resultados de las ejecuciones son más homogéneos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluación de hipótesis mediante Análisis ROC "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matriz de confusión y diagramas del clasificador en el espacio ROC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
