{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Datos import Datos\n",
    "from EstrategiaParticionado import *\n",
    "from Clasificador import *\n",
    "import numpy as np\n",
    "from sklearn import preprocessing \n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn sin Laplace para validación Simple con valores Discretos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patri\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35416666666666663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patri\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    }
   ],
   "source": [
    "dataset = Datos(\"ConjuntosDatos/tic-tac-toe.data\")\n",
    "\n",
    "# Encode categorical integer features using a one-hot aka one-of-K scheme (categorical features)\n",
    "encAtributos = preprocessing.OneHotEncoder(categorical_features=dataset.nominalAtributos[:-1],sparse=False)\n",
    "# X contendra la matriz de atributos codificada\n",
    "X = encAtributos.fit_transform(dataset.datos[:,:-1])\n",
    "\n",
    "# Y contendra la clase de cada patron\n",
    "Y =dataset.datos[:,-1] \n",
    "\n",
    "#Discretos = MultinomialNB\n",
    "#para no Laplace -> alpha = 0\n",
    "clf = MultinomialNB(alpha=0)\n",
    "\n",
    "#Validacion Simple\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(X, Y, train_size = 0.6 )\n",
    "\n",
    "#Entrena el clasificador a partir de xTrain e yTrain\n",
    "classifier = clf.fit(xTrain, yTrain)\n",
    "#Predice el resultado de xTest en base al entrenamiento\n",
    "pred = classifier.predict(xTest)\n",
    "\n",
    "# Calcula el error (1 - la precision de la clasificacion)\n",
    "error = 1  - accuracy_score(pred, yTest)\n",
    "print(error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn con Laplace para validación Simple con valores Discretos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patri\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Encode categorical integer features using a one-hot aka one-of-K scheme (categorical features)\n",
    "encAtributos = preprocessing.OneHotEncoder(categorical_features=dataset.nominalAtributos[:-1],sparse=False)\n",
    "# X contendra la matriz de atributos codificada\n",
    "X = encAtributos.fit_transform(dataset.datos[:,:-1])\n",
    "\n",
    "# Y contendra la clase de cada patron\n",
    "Y =dataset.datos[:,-1] \n",
    "\n",
    "#Discretos = MultinomialNB\n",
    "#para Laplace -> alpha = 1\n",
    "clf = MultinomialNB(alpha=1)\n",
    "\n",
    "#Validacion Simple\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(X, Y, train_size = 0.6 )\n",
    "\n",
    "#Entrena el clasificador a partir de xTrain e yTrain\n",
    "classifier = clf.fit(xTrain, yTrain)\n",
    "#Predice el resultado de xTest en base al entrenamiento\n",
    "pred = classifier.predict(xTest)\n",
    "\n",
    "# Calcula el error (1 - la precision de la clasificacion)\n",
    "error = 1  - accuracy_score(pred, yTest)\n",
    "print(error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn para validación Simple con valores Continuos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patri\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35250000000000004\n"
     ]
    }
   ],
   "source": [
    "dataset = Datos(\"ConjuntosDatos/german.data\")\n",
    "\n",
    "        \n",
    "# Encode categorical integer features using a one-hot aka one-of-K scheme (categorical features)\n",
    "encAtributos = preprocessing.OneHotEncoder(categorical_features=dataset.nominalAtributos[:-1],sparse=False)\n",
    "# X contendra la matriz de atributos codificada\n",
    "X = encAtributos.fit_transform(dataset.datos[:,:-1])\n",
    "\n",
    "# Y contendra la clase de cada patron\n",
    "Y =dataset.datos[:,-1] \n",
    "\n",
    "#Continuos = GaussianNB\n",
    "clf = GaussianNB()\n",
    "\n",
    "#Validacion Simple\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(X, Y, train_size = 0.6 )\n",
    "\n",
    "#Entrena el clasificador a partir de xTrain e yTrain\n",
    "classifier = clf.fit(xTrain, yTrain)\n",
    "#Predice el resultado de xTest en base al entrenamiento\n",
    "pred = classifier.predict(xTest)\n",
    "\n",
    "# Calcula el error (1 - la precision de la clasificacion)\n",
    "error = 1  - accuracy_score(pred, yTest)\n",
    "print(error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn sin Laplace para validación Cruzada con valores Discretos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37965224841530354 0.07553484138584828\n"
     ]
    }
   ],
   "source": [
    "dataset = Datos(\"ConjuntosDatos/tic-tac-toe.data\")\n",
    "\n",
    "# Encode categorical integer features using a one-hot aka one-of-K scheme (categorical features)\n",
    "encAtributos = preprocessing.OneHotEncoder(categorical_features=dataset.nominalAtributos[:-1],sparse=False)\n",
    "# X contendra la matriz de atributos codificada\n",
    "X = encAtributos.fit_transform(dataset.datos[:,:-1])\n",
    "\n",
    "# Y contendra la clase de cada patron\n",
    "Y =dataset.datos[:,-1] \n",
    "\n",
    "#Discretos = MultinomialNB\n",
    "#para no Laplace -> alpha = 0\n",
    "clf = MultinomialNB(alpha=1.0e-10)\n",
    "\n",
    "#Validacion Cruzada: obtenemos los resultados de las predicciones de cv iteraciones\n",
    "pred_kfolds = cross_val_score(clf, X, Y, cv = 5)\n",
    "\n",
    "#Obtenemos el error de la media de las predicciones\n",
    "media_error = 1 - pred_kfolds.mean()\n",
    "\n",
    "#Obtenemos la desviacion tipica de las predicciones\n",
    "desv_error = pred_kfolds.std()\n",
    "\n",
    "print(media_error, desv_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn con Laplace para validación Cruzada con valores Discretos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37965224841530354 0.07553484138584828\n"
     ]
    }
   ],
   "source": [
    "# Encode categorical integer features using a one-hot aka one-of-K scheme (categorical features)\n",
    "encAtributos = preprocessing.OneHotEncoder(categorical_features=dataset.nominalAtributos[:-1],sparse=False)\n",
    "# X contendra la matriz de atributos codificada\n",
    "X = encAtributos.fit_transform(dataset.datos[:,:-1])\n",
    "\n",
    "# Y contendra la clase de cada patron\n",
    "Y =dataset.datos[:,-1] \n",
    "\n",
    "#Discretos = MultinomialNB\n",
    "#para Laplace -> alpha = 1\n",
    "clf = MultinomialNB(alpha=1)\n",
    "\n",
    "#Validacion Cruzada: obtenemos los resultados de las predicciones de cv iteraciones\n",
    "pred_kfolds = cross_val_score(clf, X, Y, cv = 5)\n",
    "\n",
    "#Obtenemos el error de la media de las predicciones\n",
    "media_error = 1 - pred_kfolds.mean()\n",
    "\n",
    "#Obtenemos la desviacion tipica de las predicciones\n",
    "desv_error = pred_kfolds.std()\n",
    "\n",
    "print(media_error, desv_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn para validación Cruzada con valores Continuos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneHotEncoder(categorical_features=[1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1],\n",
      "       dtype=<class 'numpy.float64'>, handle_unknown='error',\n",
      "       n_values='auto', sparse=False)\n",
      "0.33299999999999996 0.036551333764994115\n"
     ]
    }
   ],
   "source": [
    "dataset = Datos(\"ConjuntosDatos/german.data\")\n",
    "\n",
    "        \n",
    "# Encode categorical integer features using a one-hot aka one-of-K scheme (categorical features)\n",
    "encAtributos = preprocessing.OneHotEncoder(categorical_features=dataset.nominalAtributos[:-1],sparse=False)\n",
    "# X contendra la matriz de atributos codificada\n",
    "X = encAtributos.fit_transform(dataset.datos[:,:-1])\n",
    "\n",
    "# Y contendra la clase de cada patron\n",
    "Y =dataset.datos[:,-1] \n",
    "\n",
    "#Discretos = MultinomialNB\n",
    "#para no Laplace -> alpha = 0\n",
    "clf = GaussianNB()\n",
    "\n",
    "#Validacion Cruzada: obtenemos los resultados de las predicciones de cv iteraciones\n",
    "pred_kfolds = cross_val_score(clf, X, Y, cv = 5)\n",
    "\n",
    "#Obtenemos el error de la media de las predicciones\n",
    "media_error = 1 - pred_kfolds.mean()\n",
    "\n",
    "#Obtenemos la desviacion tipica de las predicciones\n",
    "desv_error = pred_kfolds.std()\n",
    "\n",
    "print(media_error, desv_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn para KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4069999999999999 0.03742993454442579\n"
     ]
    }
   ],
   "source": [
    "# Encode categorical integer features using a one-hot aka one-of-K scheme (categorical features)\n",
    "encAtributos = preprocessing.OneHotEncoder(categorical_features=dataset.nominalAtributos[:-1],sparse=False)\n",
    "# X contendra la matriz de atributos codificada\n",
    "X = encAtributos.fit_transform(dataset.datos[:,:-1])\n",
    "\n",
    "# Y contendra la clase de cada patron\n",
    "Y =dataset.datos[:,-1] \n",
    "\n",
    "\n",
    "n_neighbors = 1\n",
    "clf = KNeighborsClassifier(n_neighbors)\n",
    "\n",
    "#Validacion Cruzada: obtenemos los resultados de las predicciones de cv iteraciones\n",
    "knn = cross_val_score(clf, X, Y, cv = 10)\n",
    "\n",
    "#Obtenemos el error de la media de las predicciones\n",
    "media_error = 1 - knn_cv.mean()\n",
    "\n",
    "#Obtenemos la desviacion tipica de las predicciones\n",
    "desv_error = knn_cv.std()\n",
    "\n",
    "print(media_error, desv_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
